## 运行爬虫

Crawlab有两种运行爬虫的方式：
1. 手动触发
2. [定时任务触发](../Schedule/README.md)

### 手动触发

1. 在 `爬虫列表` 中 `操作` 列点击 `运行` 按钮并确认，或者
2. 在 `爬虫详情` 中 `概览` 标签下点击 `运行` 按钮并确认，或者
3. 如果是 `可配置爬虫`，还可以在 `配置` 标签下点击 `运行` 按钮并确认

然后，Crawlab会提示任务已经派发到队列中去了，然后你可以在 `爬虫详情`左侧看到新创建的任务。点击任务可以导航至 `任务详情`。

### 运行类型

当点击 `运行` 按钮时，会弹出一个对话框，其中有一个 `运行类型` 的必填选项，指代您希望这个爬虫任务运行的模式，也就是运行节点的分配策略。如下图，有 3 种运行类型：所有节点、指定节点、随机。

![](http://static-docs.crawlab.cn/task-run-popup.png)

- **所有节点**：该任务在所有在线节点上同时运行，该策略比较适合大型的分布式爬虫；
- **指定节点**：指定一个在线节点上运行，该策略适合有不同拓扑结构节点分布的爬虫，例如一些节点分布在国内，另一些分布在国外；
- **随机**：系统任意分配一个节点运行该任务，该策略是最简单的运行策略，能够平均分配所有有效资源。

### 参数

在任务运行的确认对话框中，另一个可选输入项是 `参数`，这相当于 `执行命令` 的附加命令。

对于 `自定义爬虫` 来说，运行任务相当于执行一行操作命令，例如 `python spider.py`。而 `参数` 是在 `执行命令` 中附加的指令，接在 `执行命令` 后面。最后任务执行的操作命令会是 爬虫的 `执行命令` + 任务的 `参数`。

例如，执行命令为 `python spider.py`，参数为 `keyword`。最后被运行的操作命令为 `python spider.py keyword`。

`参数` 让爬虫变得更灵活，其中一个比较有用的地方是提升爬虫的复用性。例如，一个搜索引擎爬虫，需要参数化搜索的关键词，可以将关键词作为 `参数` 传入爬虫。

另一个比较有用的地方是一个爬虫项目中（这里的“爬虫项目”不是指 Crawlab 中的“项目”）有多个爬虫，例如包含多个爬虫的 `Scrapy` 爬虫项目，可以将 `scrapy crawl <spider_name>` 中的 `<spider_name>` 作为参数传入爬虫中，然后就可以通过参数来选择运行不同的爬虫了。

### 定时任务触发

`定时任务触发` 是比较常用的功能，对于`增量抓取`或对实时性有要求的任务很重要。这在 [定时任务](../Schedule/README.md) 中会详细介绍。